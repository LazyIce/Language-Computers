{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Name: Bin Xie\n",
    "\n",
    "## Names of people you worked with:\n",
    "\n",
    "## Section 0: Setup\n",
    "\n",
    "We're going to be using NLTK, Python's \"Natural Language Tool Kit\".\n",
    "\n",
    "You can read more about nltk here: http://www.nltk.org/book/, especially Chapter 2 (http://www.nltk.org/book/ch02.html)\n",
    "\n",
    "Download nltk.  You might have to run:\n",
    "  <ul> import nltk </ul>\n",
    "    <ul> nltk.download() </ul>\n",
    "        \n",
    "        \n",
    "  and then wait until it all installs.\n",
    "  \n",
    "  First let's make sure it's loaded by printing the number of words in \"Emma\".  Please run the cell below and make sure it prints out \"192427\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "emma_words = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "len(emma_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Section 1: Part-of-Speech Tagging\n",
    "\n",
    "You have probably heard of nouns, verbs, adjectives, prepositions, and so on: \"parts of speech\" (PoS).\n",
    "\n",
    "The Parts of Speech tags often used in computational linguistics are given HERE: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "This question is adopted from Lucas Champollion and Frans Adriaans.\n",
    "\n",
    "### Question 1\n",
    "Newspaper headlines are famous for being syntactically ambiguous in ways that can be funny.\n",
    "\n",
    "Without doing any programming, please manually assign PoS tags to the following (amusingly ambiguous) newspaper headlines:\n",
    "\n",
    "-- British Left Waffles on Falkland Islands\n",
    "\n",
    "-- Juvenile Court to Try Shooting Defendant\n",
    "\n",
    "-- A Tiny Force of Nature is Stronger than Thought\n",
    "\n",
    "-- Miners Refuse to Work After Death\n",
    "\n",
    "-- Iraqi head seeks arms\n",
    "\n",
    "-- Pope's Baby Steps On Gays\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "When there is more than one possible answer for a sentence, write down each answer. Does knowing the part of speech for each word remove ambiguity, or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 1\n",
    "\n",
    "-- British(NNP) Left(VBN) Waffles(NNS) on(IN) Falkland(NNP) Islands(NNP)                     \n",
    "\n",
    "-- Juvenile(JJ) Court(NN) to(TO) Try(VB) Shooting(VBG) Defendant(NN)   \n",
    "      \n",
    "-- A(DT) Tiny(JJ) Force(NN) of(IN) Nature(NN) is(VBZ) Stronger(JJR) than(IN) Thought(NN)\n",
    "\n",
    "-- Miners(NNS) Refuse(VBP) to(TO) Work(VB) After(IN) Death(NN)\n",
    "\n",
    "-- Iraqi(JJ) head(NN) seeks(VBZ) arms(NNS)\n",
    "\n",
    "-- Pope's(PBR$) Baby(NN) Steps(VBZ) On(IN) Gays(NNS)\n",
    "\n",
    "I think knowing the part of speech for each word removes ambiguilty to some extent. For example, knowing \"British\" is NNP really helps a lot to understand \"British Left Waffles on Falkland Islands\". However, there is still ambiguity. For example, \"Iriqi head seeks arms\". \"head\" can refer to the leader of a group or the head organ when it's NN. We still can not get the correct meaning from the speaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "See the following example of how to automatically tag a headline using NLTK's part-of-speech tagger:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('World', 'NNP'), ('Leaders', 'NNP'), ('Seek', 'NNP'), ('Agreement', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "headline=\"World  Leaders  Seek  Agreement\"\n",
    "\n",
    "words=nltk.word_tokenize(headline)\n",
    "# this function turns the string into a list of words\n",
    "\n",
    "tags=nltk.pos_tag(words)#  This  function takes in a list of words and then print  out  a  list  of  (word,tag)  pairs\n",
    "\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now please automatically tag all of the news headlines from Question 1.\n",
    "\n",
    "Are any of the headlines tagged in a way that the author probably did not intend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('British', 'JJ'), ('Left', 'NNP'), ('Waffles', 'NNP'), ('on', 'IN'), ('Falkland', 'NNP'), ('Islands', 'NNP')]\n",
      "[('Juvenile', 'NNP'), ('Court', 'NNP'), ('to', 'TO'), ('Try', 'VB'), ('Shooting', 'NNP'), ('Defendant', 'NNP')]\n",
      "[('A', 'DT'), ('Tiny', 'NNP'), ('Force', 'NNP'), ('of', 'IN'), ('Nature', 'NNP'), ('is', 'VBZ'), ('Stronger', 'JJR'), ('than', 'IN'), ('Thought', 'NN')]\n",
      "[('Miners', 'NNS'), ('Refuse', 'NNP'), ('to', 'TO'), ('Work', 'VB'), ('After', 'IN'), ('Death', 'NNP')]\n",
      "[('Iraqi', 'NNP'), ('head', 'NN'), ('seeks', 'NN'), ('arms', 'NNS')]\n",
      "[('Pope', 'NNP'), (\"'s\", 'POS'), ('Baby', 'NNP'), ('Steps', 'NNP'), ('On', 'IN'), ('Gays', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "def tag_pos(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tags = nltk.pos_tag(words)\n",
    "    print(tags)\n",
    "    \n",
    "tag_pos('British Left Waffles on Falkland Islands')\n",
    "tag_pos('Juvenile Court to Try Shooting Defendant')\n",
    "tag_pos('A Tiny Force of Nature is Stronger than Thought')\n",
    "tag_pos('Miners Refuse to Work After Death')\n",
    "tag_pos('Iraqi head seeks arms')\n",
    "tag_pos(\"Pope's Baby Steps On Gays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of them are tagged in a way that the author probably didn't intent. Since the first letter of many words are capitalized, these words are tagged \"NNP\". Also, \"British\" is tagged \"JJ\". \"Tiny\", \"Refuse\", \"seeks\" and \"steps\" are tagged \"NNP\". It looks like that the uppercase and lowercase have influence on the tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 - Edit Distance\n",
    "\n",
    "adapted from Lucas Champollion and Frans Adriaans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A  user  types  “halvs”  in  a  document.  This word is a mis-spelling, which we can see from the fact that it does not occur in any dictionary, nor in any set of words taken from a corpus of correctly-spelled words.\n",
    " \n",
    "The  computer  comes  up  with  four  candidate  corrections (as for how these are generated, stay tuned):  -  halves  -  calves  -  halts -  helps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Based only on your intuition (no math or programming needed), please rank those corrections from most to least likely (what did the writer most likely intend?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 3\n",
    "\n",
    "halves > halts > calves > helps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Next, we'll import a function for calculating edit distance, already given to us in NLTK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between 'halves' and  'halvs'\n",
      "1\n",
      "distance between 'calves' and  'halvs'\n",
      "2\n",
      "distance between 'halts' and  'halvs'\n",
      "1\n",
      "distance between 'helps' and  'halvs'\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "candidates = [\"halves\", \"calves\", \"halts\", \"helps\"]\n",
    "\n",
    "for cand in candidates:\n",
    "    print(\"distance between '\" + cand + \"' and  'halvs'\")\n",
    "    print(edit_distance(cand,\"halvs\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please explain all 4 of these numbers.  How are they calculated?\n",
    "\n",
    "(As a hint, the operations allowed in \"edit distance\" -- each with a cost of 1 -- are as follows....)\n",
    "\n",
    "insertion: insert a character\n",
    "\n",
    "deletion: delete a character\n",
    "\n",
    "transposition: reverse the order of 2 characters\n",
    "\n",
    "substitution/replacement: replace 1 character with another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 4\n",
    "\n",
    "'halvs' -> 'halves':\n",
    "- insert 'e' between 'v' and 's'\n",
    "\n",
    "'halvs' -> 'calves':\n",
    "- sustitute 'h' with 'c'\n",
    "- insert 'e' between 'v' and 's'\n",
    "\n",
    "'halvs' -> 'halts':\n",
    "- substitute 'v' with 't'\n",
    "\n",
    "'halvs' -> 'helps':\n",
    "- substitute 'a' with 'e'\n",
    "- substitute 'v' with 'p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What further information could you use to decide which of the two closest corrections by edit distance (\"halves\" and \"halts\") should be ranked higher?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 5\n",
    "\n",
    "1. We can look at the contexts and select the best candidate based on constituent.\n",
    "2. We can look at the former several words or following several words and select the best candidate based on n-gram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Imagine a common mis-spelling of your own name.\n",
    "\n",
    "Use NLTK to calculate the edit distance between the mis-spelling and the correct spelling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "my_name = 'Bin Xie';\n",
    "misspelling_name = 'Bing Xee';\n",
    "\n",
    "print(edit_distance(cand,\"halvs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Presumably, other possible mis-spellings are also within the same edit-distance of your correctly spelled name as the common mis-spelling you indicated in Question 13.\n",
    "\n",
    "Give an example of some of these other possible mis-spellings.\n",
    "\n",
    "Can you write a function in Python to generate all possibilities within an edit distance of 1 of your actual name?\n",
    "\n",
    "Why do you think these less-common mis-spellings are less common?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 7\n",
    "\n",
    "Some examples of these other possible mis-spellings: Ben Xee, Bing Sie, Bin She."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bin Xixe', 'Bin Xik', 'Bion Xie', 'Bin kie', 'Biq Xie', 'sBin Xie', 'Byn Xie', 'Bin Xxie', 'Bin Xiae', 'Bib Xie', 'Bin Xire', 'Bijn Xie', 'BinsXie', 'fin Xie', 'Bing Xie', 'Binw Xie', 'Bin Xiqe', 'Bcn Xie', 'Bin Xqe', 'BintXie', 'kBin Xie', 'Bbin Xie', 'Binq Xie', 'Bin Xier', 'Bin nXie', 'Bin Xies', 'Bin Xib', 'Bqin Xie', 'Bin Xsie', 'Bind Xie', 'Bpn Xie', 'Binx Xie', 'Bin Xtie', 'Bin fie', 'Bin Xipe', 'Bin Xiq', 'Bin sXie', 'Bibn Xie', 'Bin tie', 'kin Xie', 'Bin bXie', 'Bin Xte', 'Bvn Xie', 'Bin Xeie', 'Bin mie', 'Bin Xif', 'Bfn Xie', 'Bjin Xie', 'BinzXie', 'Bit Xie', 'zBin Xie', 'Bin Xieu', 'Bin eXie', 'Bid Xie', 'Bin jXie', 'Bipn Xie', 'Bin Xiey', 'Bin Xil', 'Bin Xfe', 'Binu Xie', 'Bqn Xie', 'Bin Xi', 'Bien Xie', 'Bin Xiy', 'Bin oXie', 'Biv Xie', 'Bcin Xie', 'Bign Xie', 'Btn Xie', 'Bin Xce', 'Bin Xxe', 'Bin Xiep', 'Bin Xige', 'Bin Xze', 'Bni Xie', 'Bin Xike', 'Bin Xij', 'Bin Xin', 'yBin Xie', 'rin Xie', 'Bin Xiem', 'Bik Xie', 'Bi nXie', 'Bic Xie', 'Bizn Xie', 'Bin Xii', 'Binn Xie', 'BinkXie', 'Bi Xie', 'Bin Xihe', 'Bin pXie', 'Bihn Xie', 'Bin gXie', 'Bin Xzie', 'Bmin Xie', 'Biyn Xie', 'Bin Xcie', 'in Xie', 'lin Xie', 'Bin Xbie', 'Bin Xe', 'vin Xie', 'Bin kXie', 'Bin Xje', 'Bih Xie', 'Bin Xiex', 'Bis Xie', 'Bin Xuie', 'gin Xie', 'Binm Xie', 'Bin Xiec', 'Bin Xiei', 'iBin Xie', 'Bvin Xie', 'Bin Xre', 'Bin Xied', 'Bwin Xie', 'Biw Xie', 'Bin Xien', 'Bin Xieb', 'Bin Xye', 'Biu Xie', 'Bin Xvie', 'Binz Xie', 'Bin Xis', 'Bin dXie', 'Bin Xid', 'Binv Xie', 'Bin vie', 'Bin Xie', 'din Xie', 'ein Xie', 'Binj Xie', 'Bin Xmie', 'Bfin Xie', 'BinqXie', 'Bin Xife', 'Bisn Xie', 'Buin Xie', 'Bin Xiie', 'Bin Xpe', 'Bnin Xie', 'Bin Xqie', 'Bxin Xie', 'Bin Xue', 'Bin Xfie', 'Bin Xile', 'Bin Xir', 'Bio Xie', 'pBin Xie', 'BinrXie', 'Bin Xiue', 'Bin Xip', 'Bin aXie', 'Bun Xie', 'Bicn Xie', 'Ben Xie', 'Bin tXie', 'Bin Xit', 'Bdin Xie', 'Bin Xiet', 'Bzin Xie', 'BinhXie', 'Bkin Xie', 'Bbn Xie', 'xin Xie', 'Bin wie', 'Bin Xnie', 'Biy Xie', 'BinxXie', 'Bgin Xie', 'Bin Xio', 'Bin uie', 'Bin Xle', 'Bin iXe', 'Bin xXie', 'Bmn Xie', 'Bin Xjie', 'oin Xie', 'pin Xie', 'Bin lie', 'Bikn Xie', 'Bin cXie', 'Bin Xiwe', 'tBin Xie', 'Bin Xieh', 'Bin Xve', 'Bin qXie', 'Bin Xief', 'Bin Xdie', 'qBin Xie', 'cBin Xie', 'Binr Xie', 'fBin Xie', 'Bin Xiee', 'Bin zie', 'Bin Xise', 'zin Xie', 'BinyXie', 'Bin Xkie', 'Bin wXie', 'Bin die', 'Bin Xyie', 'Boin Xie', 'Bin Xiej', 'BiniXie', 'BinaXie', 'BinnXie', 'Bil Xie', 'bBin Xie', 'Bin gie', 'nin Xie', 'Bin Xive', 'Bin qie', 'BinjXie', 'Bin xie', 'Binl Xie', 'Bein Xie', 'Bif Xie', 'Bin Xde', 'Bin pie', 'Ban Xie', 'Brin Xie', 'Bin Xiek', 'Binf Xie', 'Bin lXie', 'Bin hXie', 'Bifn Xie', 'Bin Xide', 'BinpXie', 'nBin Xie', 'Btin Xie', 'lBin Xie', 'Bin Xge', 'Big Xie', 'Bin Xig', 'Bin Xiv', 'Bjn Xie', 'BinX ie', 'Bin aie', 'BinoXie', 'Bivn Xie', 'jin Xie', 'Bin Xioe', 'Bin Xae', 'Binh Xie', 'oBin Xie', 'Bin iXie', 'Bino Xie', 'Bin bie', 'Bhin Xie', 'Bidn Xie', 'eBin Xie', 'Bhn Xie', 'Bin Xibe', 'Bij Xie', 'Biun Xie', 'xBin Xie', 'Bin Xhie', 'min Xie', 'Blin Xie', 'Bin Xiz', 'qin Xie', 'BinmXie', 'iBn Xie', 'win Xie', 'BinvXie', 'Bin ie', 'Bin Xim', 'Bnn Xie', 'BingXie', 'Bine Xie', 'Bin Xiw', 'Bin fXie', 'Bin Xic', 'Bin Xiez', 'sin Xie', 'Biwn Xie', 'iin Xie', 'Bin Xiea', 'Biin Xie', 'Bin Xize', 'Bin iie', 'mBin Xie', 'Bsin Xie', 'Bin Xieq', 'gBin Xie', 'BinXie', 'Bin Xwe', 'Bini Xie', 'Bin Xieo', 'Bin Xiye', 'Binb Xie', 'bin Xie', 'Bin uXie', 'Bip Xie', 'yin Xie', 'Bin zXie', 'Bpin Xie', 'Bin Xke', 'hin Xie', 'Bitn Xie', 'Bin Xrie', 'BincXie', 'Bin nie', 'Bin oie', 'Bin Xiu', 'Bin rXie', 'Bwn Xie', 'Bin Xix', 'Bin Xime', 'Bin sie', 'uin Xie', 'BinwXie', 'Bain Xie', 'Bin Xgie', 'Bin Xije', 'jBin Xie', 'Bin hie', 'Bimn Xie', 'Bin Xiel', 'Bin Xei', 'uBin Xie', 'Bir Xie', 'Bln Xie', 'Bin Xhe', 'Bin Xine', 'Bink Xie', 'Bin vXie', 'Bzn Xie', 'Bin Xpie', 'Bdn Xie', 'Bim Xie', 'Bin mXie', 'Brn Xie', 'BinlXie', 'Bin Xme', 'Bn Xie', 'Bin yXie', 'dBin Xie', 'aBin Xie', 'Bix Xie', 'Bxn Xie', 'Binc Xie', 'Biny Xie', 'Bin cie', 'Bin Xiev', 'ain Xie', 'BineXie', 'Bin Xaie', 'Bin eie', 'tin Xie', 'wBin Xie', 'Bin Xice', 'Bin jie', 'Bin Xlie', 'Bins Xie', 'Bint Xie', 'Bin Xih', 'Bgn Xie', 'Bixn Xie', 'cin Xie', 'Bon Xie', 'Bie Xie', 'hBin Xie', 'Birn Xie', 'Bin Xite', 'Bina Xie', 'Bian Xie', 'Bin yie', 'Bsn Xie', 'Bia Xie', 'BinbXie', 'Bin Xbe', 'vBin Xie', 'Bin Xwie', 'Binp Xie', 'Bin Xse', 'Bin Xia', 'Bii Xie', 'Biqn Xie', 'Bin Xieg', 'Biln Xie', 'Bin rie', 'BinuXie', 'BindXie', 'Bin Xee', 'rBin Xie', 'BinfXie', 'Bin Xoie', 'Bin Xoe', 'Bin Xne', 'Bin Xiew', 'Bkn Xie', 'Biz Xie', 'Byin Xie'}\n"
     ]
    }
   ],
   "source": [
    "# It refers to the Peter Norvig's Spell-Checker.\n",
    "def generate_misspellings_with_edit_distance_one(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes = [left + right[1:] for left, right in splits if right]\n",
    "    transposes = [left + right[1] + right[0] + right[2:] for left, right in splits if len(right)>1]\n",
    "    replaces   = [left + c + right[1:] for left, right in splits if right for c in letters]\n",
    "    inserts    = [left + c + right for left, right in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "print(generate_misspellings_with_edit_distance_one('Bin Xie'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Some mis-spellings don't have the same pronunciation of my correct name so that they are less common.\n",
    "2. Some letters are far way from each other on the keyboard so that these mis-spellings are less common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 - Peter Norvig's Spell-Checker\n",
    "\n",
    "The following code is adapted from Google research director Peter Norvig: https://norvig.com/spell-correct.html (please read that web page for discussion).  It's a spell-checker that reads in a word and outputs a spell-checked version of that word.\n",
    "\n",
    "First, we use the Brown Corpus to get a dictionary of words and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import brown\n",
    "\n",
    "\n",
    "WORDS = Counter(brown.words())\n",
    "# we are using the Brown Corpus (part of NLTK) \n",
    "#to get a dictionary of correctly spelled words and their frequencies.\n",
    "# WORDS is a DICTIONARY where the keys are words and the values are the number of \n",
    "# occurrences of that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make that idea concrete by printing out the 20 key/value pairs from WORDS with the highest values.\n",
    "\n",
    "Note that \"u\" means the string is in Unicode.\n",
    "\n",
    "Not surprisingly, when you run the cell below, you will see that \"the, and, of, to\", and various punctuation marks are very common words in the Brown Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 62713),\n",
       " (',', 58334),\n",
       " ('.', 49346),\n",
       " ('of', 36080),\n",
       " ('and', 27915),\n",
       " ('to', 25732),\n",
       " ('a', 21881),\n",
       " ('in', 19536),\n",
       " ('that', 10237),\n",
       " ('is', 10011),\n",
       " ('was', 9777),\n",
       " ('for', 8841),\n",
       " ('``', 8837),\n",
       " (\"''\", 8789),\n",
       " ('The', 7258),\n",
       " ('with', 7012),\n",
       " ('it', 6723),\n",
       " ('as', 6706),\n",
       " ('he', 6566),\n",
       " ('his', 6466)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, here is Peter Norvig's spell-checker.  (Again, see his blog post for discussion: https://norvig.com/spell-correct.html.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrected\n",
      "correct\n",
      "georiga\n",
      "Georgia\n"
     ]
    }
   ],
   "source": [
    "print(correction(\"corected\"))\n",
    "\n",
    "print(correction(\"correct\"))\n",
    "\n",
    "print(correction(\"georiga\"))\n",
    "\n",
    "print(correction(\"Georiga\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What does Norvig's spell-checker do with a word that is ALREADY spelled correctly and does not need to be corrected?  How does the spell-checker \"know\" that the word is already spelled right?  (1-2 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 8\n",
    "\n",
    "For the word that is already spelled correctly and doesn't need to be corrected,\n",
    "- if word is known in the dictionary, it will return the word directly.\n",
    "- if word is unknown in the dictionary and has no candidates in the dictionary, it will return the word directly.\n",
    "- if word is not in the dictionary and has candidates in the dictionary, it may return the most possible candidate.\n",
    "\n",
    "To check a word is already spelled right,\n",
    "- It will generate the candidates which contain original word ,words within the edit distance 1 and words within the edit distance2.\n",
    "- The author assumes that all known words of edit distance 1 are infinitely more probable than known words of edit distance 2, and infinitely less probable than a known word of edit distance 0. So if the word is spelled correct, it will return from the candidate directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "What does Norvig's spell-checker do with a word that IS mis-spelled?\n",
    "\n",
    "How is such a mis-spelling identified?\n",
    "\n",
    "How are the candidate corrections generated?\n",
    "\n",
    "How is the best candidate chosen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 9\n",
    "\n",
    "With a word that is mis-spelled, Norvig's spell-checker will return the correct word if there is one in the dictionary within the edit distance 1 or 2. Otherwise, it will return the original word.\n",
    "\n",
    "In the candidates, Norvig's spell-checker will check whether the original word is in the dictionary. If the original word is not in the dictionary, it's mis-spelling.\n",
    "\n",
    "The candidate corrections contain the original word, words within the edit distance 1 and words within the edit distance2 in the dictionary.\n",
    "\n",
    "To choose the best candidate, \n",
    "- The original word, if it is known; otherwise\n",
    "- The list of known words at edit distance one away, if there are any; otherwise\n",
    "- The list of known words at edit distance two away, if there are any; otherwise\n",
    "- The original word, even though it is not known.\n",
    "To choose the best candidate from the list of known words at the same edit distance, it based on the possibility of the words. The possibility of the words come from counting the number of times each word appears in the source text files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "An \"OOV item\" is an \"out-of-vocabulary item.\"  Norvig's spellchecker is based on the idea that all OOV items need to be spell-corrected to be turned into in-vocabulary items.  But actually, this is not true; perhaps the word is simply a correct spelling of a NEW word that the spellchecker has never seen before.\n",
    "\n",
    "This Twitter account (https://twitter.com/nyt_first_said?lang=en) automatically documents new words used for the first time in the New York Times.  Even though they are all by definition OOV items, none of them are typos, so they should actually not be corrected by a spell-checker.  Learning how to deal with OOV items -- both their spelling and their meaning -- is an important topic in current NLP research.  A graduate student at Georgia Tech named Yuval Pinter is working on this topic for his thesis, partly using these NYT data.\n",
    "\n",
    "Please spend some time reading these new words.  Can you group them into any meaningful categories?  Can you brainstorm any possible ways that thy might be (automatically) recognized as new words rather than mis-spellings of existing words?  For example, can you think of any way to automate what you are already doing yourself when you recognize them as such?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 10\n",
    "\n",
    "I think we can group them into the category called \"Modern Words\".\n",
    "\n",
    "We can use python urllib to capture all the new words from the above link and add these new words to the source dictionary. In this way, our spelling checker can recognize them.\n",
    "\n",
    "For example, when I met a new word, I will remember them in my mind or just write it down. So when I meet this word again, I will recognize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Please *implement* ONE improvement to Norvig's spell-checker (i.e., in Python).  Explain what you changed and why.  If you are not at a Python level where you can implement it, at least write in detail about what you want to do, and how you might try to implement it in code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 11\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Please \"meta-cognitively\" reflect on what you have learned so far in this class, as well as what you are finding most interesting, challenging, confusing, effective/ineffective, or intimidating.  I want to use this information to make small changes going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 12\n",
    "\n",
    "What I have learned:\n",
    "- Encoding: writing system type(alphabetic, syllaic, logographic), encoding in computer(ASCII, Unicode), N-gram\n",
    "- spelling-checking: error detection(non-word errors/real word errors), edit distance, descriptive/prescriptive grammer, constituent, ambiguity\n",
    "- how to do search: precision/recall, pagerank, iftdf, keyword optimization\n",
    "\n",
    "Most interesting:\n",
    "- spelling checking and search are interesting since they are related to our daily life closely. Also, there are more tools to have a try.\n",
    "- Paper representations are interesting. I still remember the paper whose conclusion is that negation is negative. I can learn some new points I didn't met before in these papers.\n",
    "\n",
    "Most challenging and confusing:\n",
    "- When we talked about ambiguity and part of speech, these topics are a little difficult for non-native English speakers like me. I need to spend more time to explore the grammer or lexcal more.\n",
    "\n",
    "Most effective:\n",
    "- Quiz is good. Since the questions are fundamental and I can revise the new knowledge again. It's really helpful to have a good understanding of the key points in each chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Please write your own question and then answer it!  (One suggestion: Implement a proposed improvement to Norvig's spell-checker.)\n",
    "\n",
    "The question can be a programming question or a conceptual question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your question and answer to Question 13\n",
    "\n",
    "(PLEASE PUT YOUR QUESTION AND ANSWER HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
