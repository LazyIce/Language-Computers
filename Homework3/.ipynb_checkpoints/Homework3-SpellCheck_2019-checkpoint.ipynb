{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Name: Bin Xie\n",
    "\n",
    "## Names of people you worked with:\n",
    "\n",
    "## Section 0: Setup\n",
    "\n",
    "We're going to be using NLTK, Python's \"Natural Language Tool Kit\".\n",
    "\n",
    "You can read more about nltk here: http://www.nltk.org/book/, especially Chapter 2 (http://www.nltk.org/book/ch02.html)\n",
    "\n",
    "Download nltk.  You might have to run:\n",
    "  <ul> import nltk </ul>\n",
    "    <ul> nltk.download() </ul>\n",
    "        \n",
    "        \n",
    "  and then wait until it all installs.\n",
    "  \n",
    "  First let's make sure it's loaded by printing the number of words in \"Emma\".  Please run the cell below and make sure it prints out \"192427\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "emma_words = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "len(emma_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Section 1: Part-of-Speech Tagging\n",
    "\n",
    "You have probably heard of nouns, verbs, adjectives, prepositions, and so on: \"parts of speech\" (PoS).\n",
    "\n",
    "The Parts of Speech tags often used in computational linguistics are given HERE: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "This question is adopted from Lucas Champollion and Frans Adriaans.\n",
    "\n",
    "### Question 1\n",
    "Newspaper headlines are famous for being syntactically ambiguous in ways that can be funny.\n",
    "\n",
    "Without doing any programming, please manually assign PoS tags to the following (amusingly ambiguous) newspaper headlines:\n",
    "\n",
    "-- British Left Waffles on Falkland Islands\n",
    "\n",
    "-- Juvenile Court to Try Shooting Defendant\n",
    "\n",
    "-- A Tiny Force of Nature is Stronger than Thought\n",
    "\n",
    "-- Miners Refuse to Work After Death\n",
    "\n",
    "-- Iraqi head seeks arms\n",
    "\n",
    "-- Pope's Baby Steps On Gays\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "When there is more than one possible answer for a sentence, write down each answer. Does knowing the part of speech for each word remove ambiguity, or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 1\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "See the following example of how to automatically tag a headline using NLTK's part-of-speech tagger:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('World', 'NNP'), ('Leaders', 'NNP'), ('Seek', 'NNP'), ('Agreement', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "headline=\"World  Leaders  Seek  Agreement\"\n",
    "\n",
    "words=nltk.word_tokenize(headline)\n",
    "# this function turns the string into a list of words\n",
    "\n",
    "tags=nltk.pos_tag(words)#  This  function takes in a list of words and then print  out  a  list  of  (word,tag)  pairs\n",
    "\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now please automatically tag all of the news headlines from Question 1.\n",
    "\n",
    "Are any of the headlines tagged in a way that the author probably did not intend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 2\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 - Edit Distance\n",
    "\n",
    "adapted from Lucas Champollion and Frans Adriaans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A  user  types  “halvs”  in  a  document.  This word is a mis-spelling, which we can see from the fact that it does not occur in any dictionary, nor in any set of words taken from a corpus of correctly-spelled words.\n",
    " \n",
    "The  computer  comes  up  with  four  candidate  corrections (as for how these are generated, stay tuned):  -  halves  -  calves  -  halts -  helps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Based only on your intuition (no math or programming needed), please rank those corrections from most to least likely (what did the writer most likely intend?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 3\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Next, we'll import a function for calculating edit distance, already given to us in NLTK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between 'halves' and  'halvs'\n",
      "1\n",
      "distance between 'calves' and  'halvs'\n",
      "2\n",
      "distance between 'halts' and  'halvs'\n",
      "1\n",
      "distance between 'helps' and  'halvs'\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "candidates = [\"halves\", \"calves\", \"halts\", \"helps\"]\n",
    "\n",
    "for cand in candidates:\n",
    "    print(\"distance between '\" + cand + \"' and  'halvs'\")\n",
    "    print(edit_distance(cand,\"halvs\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please explain all 4 of these numbers.  How are they calculated?\n",
    "\n",
    "(As a hint, the operations allowed in \"edit distance\" -- each with a cost of 1 -- are as follows....)\n",
    "\n",
    "insertion: insert a character\n",
    "\n",
    "deletion: delete a character\n",
    "\n",
    "transposition: reverse the order of 2 characters\n",
    "\n",
    "substitution/replacement: replace 1 character with another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 4\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What further information could you use to decide which of the two closest corrections by edit distance (\"halves\" and \"halts\") should be ranked higher?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 5\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Imagine a common mis-spelling of your own name.\n",
    "\n",
    "Use NLTK to calculate the edit distance between the mis-spelling and the correct spelling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 6\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Presumably, other possible mis-spellings are also within the same edit-distance of your correctly spelled name as the common mis-spelling you indicated in Question 13.\n",
    "\n",
    "Give an example of some of these other possible mis-spellings.\n",
    "\n",
    "Can you write a function in Python to generate all possibilities within an edit distance of 1 of your actual name?\n",
    "\n",
    "Why do you think these less-common mis-spellings are less common?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 7\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 - Peter Norvig's Spell-Checker\n",
    "\n",
    "The following code is adapted from Google research director Peter Norvig: https://norvig.com/spell-correct.html (please read that web page for discussion).  It's a spell-checker that reads in a word and outputs a spell-checked version of that word.\n",
    "\n",
    "First, we use the Brown Corpus to get a dictionary of words and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import brown\n",
    "\n",
    "\n",
    "WORDS = Counter(brown.words())\n",
    "# we are using the Brown Corpus (part of NLTK) \n",
    "#to get a dictionary of correctly spelled words and their frequencies.\n",
    "# WORDS is a DICTIONARY where the keys are words and the values are the number of \n",
    "# occurrences of that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make that idea concrete by printing out the 20 key/value pairs from WORDS with the highest values.\n",
    "\n",
    "Note that \"u\" means the string is in Unicode.\n",
    "\n",
    "Not surprisingly, when you run the cell below, you will see that \"the, and, of, to\", and various punctuation marks are very common words in the Brown Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 62713),\n",
       " (',', 58334),\n",
       " ('.', 49346),\n",
       " ('of', 36080),\n",
       " ('and', 27915),\n",
       " ('to', 25732),\n",
       " ('a', 21881),\n",
       " ('in', 19536),\n",
       " ('that', 10237),\n",
       " ('is', 10011),\n",
       " ('was', 9777),\n",
       " ('for', 8841),\n",
       " ('``', 8837),\n",
       " (\"''\", 8789),\n",
       " ('The', 7258),\n",
       " ('with', 7012),\n",
       " ('it', 6723),\n",
       " ('as', 6706),\n",
       " ('he', 6566),\n",
       " ('his', 6466)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, here is Peter Norvig's spell-checker.  (Again, see his blog post for discussion: https://norvig.com/spell-correct.html.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrected\n",
      "correct\n",
      "georiga\n",
      "Georgia\n"
     ]
    }
   ],
   "source": [
    "print(correction(\"corected\"))\n",
    "\n",
    "print(correction(\"correct\"))\n",
    "\n",
    "print(correction(\"georiga\"))\n",
    "\n",
    "print(correction(\"Georiga\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What does Norvig's spell-checker do with a word that is ALREADY spelled correctly and does not need to be corrected?  How does the spell-checker \"know\" that the word is already spelled right?  (1-2 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 8\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "What does Norvig's spell-checker do with a word that IS mis-spelled?\n",
    "\n",
    "How is such a mis-spelling identified?\n",
    "\n",
    "How are the candidate corrections generated?\n",
    "\n",
    "How is the best candidate chosen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 9\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "An \"OOV item\" is an \"out-of-vocabulary item.\"  Norvig's spellchecker is based on the idea that all OOV items need to be spell-corrected to be turned into in-vocabulary items.  But actually, this is not true; perhaps the word is simply a correct spelling of a NEW word that the spellchecker has never seen before.\n",
    "\n",
    "This Twitter account (https://twitter.com/nyt_first_said?lang=en) automatically documents new words used for the first time in the New York Times.  Even though they are all by definition OOV items, none of them are typos, so they should actually not be corrected by a spell-checker.  Learning how to deal with OOV items -- both their spelling and their meaning -- is an important topic in current NLP research.  A graduate student at Georgia Tech named Yuval Pinter is working on this topic for his thesis, partly using these NYT data.\n",
    "\n",
    "Please spend some time reading these new words.  Can you group them into any meaningful categories?  Can you brainstorm any possible ways that thy might be (automatically) recognized as new words rather than mis-spellings of existing words?  For example, can you think of any way to automate what you are already doing yourself when you recognize them as such?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 10\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Please *implement* ONE improvement to Norvig's spell-checker (i.e., in Python).  Explain what you changed and why.  If you are not at a Python level where you can implement it, at least write in detail about what you want to do, and how you might try to implement it in code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 11\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Please \"meta-cognitively\" reflect on what you have learned so far in this class, as well as what you are finding most interesting, challenging, confusing, effective/ineffective, or intimidating.  I want to use this information to make small changes going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer to Question 12\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Please write your own question and then answer it!  (One suggestion: Implement a proposed improvement to Norvig's spell-checker.)\n",
    "\n",
    "The question can be a programming question or a conceptual question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your question and answer to Question 13\n",
    "\n",
    "(PLEASE PUT YOUR QUESTION AND ANSWER HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
