{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector representations of words and documents\n",
    "\n",
    "This homework is significantly adapted by Lelia Glass from one developed at UPenn by Daphne Ippolito, Anne Cocos, Stephen Mayhew, and Chris Callison-Burch.  \n",
    "\n",
    "An important idea throughout this assignment (and in computer science in general these days) is VECTORIZATION: the idea of performing operations on entire matrices all at once, rather than writing \"for loops\" for each individual element.  Even when you understand how to calculate each individual element on its own, \"vectorizing\" the computation can be a bit tricky, so don't worry if you don't understand it all yet.  This is a learning process!\n",
    "\n",
    "I also want to point out that even if you don't know much programming, you should be able to follow along in this assignment, which asks you to READ and UNDERSTAND code more than writing it yourself.  Just try to understand as much as you can, and you'll move forward in your learning process, even if you do not understand it all yet.  That's okay!\n",
    "\n",
    "The assignment is based on Chapter 6 of Jurafsky and Martin (3rd Edition).  Please read that chapter to fully understand what's happening here.  You can also check out these slides: https://web.stanford.edu/~jurafsky/li15/lec3.vector.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import subprocess\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out how this function works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term-by-document matrix\n",
    "\n",
    "First, we write code to create a term-by-document matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_term_document_matrix(line_tuples, document_names, vocab):\n",
    "  '''Returns a numpy array containing the term document matrix for the input lines.\n",
    "  Inputs:\n",
    "    line_tuples: A list of tuples, containing the name of the document and \n",
    "    a tokenized line from that document.\n",
    "    document_names: A list of the document names\n",
    "    vocab: A list of the tokens in the vocabulary\n",
    "  Let m = len(vocab) and n = len(document_names).\n",
    "  Returns:\n",
    "    td_matrix: A mxn numpy array where the number of rows is the number of words\n",
    "        and each column corresponds to a document. A_ij contains the\n",
    "        frequency with which word i occurs in document j.\n",
    "  '''\n",
    "  vocab_to_id = dict(zip(vocab, range(0, len(vocab))))\n",
    "  docname_to_id = dict(zip(document_names, range(0, len(document_names))))\n",
    "  rows = len(vocab)\n",
    "  print(\"number of words =\" + str(rows))\n",
    "  cols = len(document_names)\n",
    "  print(\"number of documents = \" + str(cols))\n",
    "  td_matrix = np.zeros(shape=(rows, cols))\n",
    "  for tuple in line_tuples:\n",
    "        doc_name = tuple[0]\n",
    "        doc_id = docname_to_id[doc_name]\n",
    "        words = tuple[1]\n",
    "        for word in words:\n",
    "            vocab_id = vocab_to_id[word]\n",
    "            td_matrix[vocab_id, doc_id] += 1\n",
    "\n",
    "  return td_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo (and debugging) on a tiny corpus\n",
    "\n",
    "We illustrate with a tiny, manageable, understandable corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Line Tuples\n",
      "(('cheese_and_crackers', ['cheese', 'and', 'crackers']), ('wine_and_cheese', ['wine', 'and', 'cheese']))\n",
      "##Doc Names\n",
      "['cheese_and_crackers', 'wine_and_cheese']\n",
      "##Vocab\n",
      "['and', 'wine', 'crackers', 'cheese']\n"
     ]
    }
   ],
   "source": [
    "line_tuples_demo = ((\"cheese_and_crackers\", \n",
    "                [\"cheese\", \"and\", \"crackers\"]), \n",
    "               (\"wine_and_cheese\", \n",
    "                [\"wine\", \"and\", \"cheese\"]), \n",
    "            \n",
    "        )\n",
    "\n",
    "vocab_demo = set()\n",
    "doc_names_demo = []\n",
    "\n",
    "def create_demo(line_tuples_demo):\n",
    "    for tup in line_tuples_demo:\n",
    "        doc_name = tup[0]\n",
    "        doc_names_demo.append(doc_name)\n",
    "        words = tup[1]\n",
    "        for word in words:\n",
    "            vocab_demo.add(word)\n",
    "    return list(vocab_demo), doc_names_demo\n",
    "\n",
    "vocab_demo, doc_names_demo = create_demo(line_tuples_demo)\n",
    "\n",
    "print(\"##Line Tuples\")\n",
    "print(line_tuples_demo)\n",
    "print(\"##Doc Names\")\n",
    "print(doc_names_demo)\n",
    "print(\"##Vocab\")\n",
    "print(vocab_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to create a term-document matrix just on this small example, to see exactly how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words =4\n",
      "number of documents = 2\n",
      "[[1. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(create_term_document_matrix(line_tuples_demo, doc_names_demo, vocab_demo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "What does this matrix represent?  (Please choose an element of the matrix, indicate its row/column, and explain its meaning.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 1\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term-context matrix\n",
    "\n",
    "Now we are creating a term-context matrix.  You can change the size of the context window as an argument to the \"create_term_context_matrix\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_term_context_matrix(tuples, vocab, context_window_size=1):\n",
    "  '''Returns a numpy array containing the term context matrix for the input lines.\n",
    "  Inputs:\n",
    "    line_tuples: A list of tuples, containing the name of the document and \n",
    "    a tokenized line from that document.\n",
    "    vocab: A list of the tokens in the vocabulary\n",
    "  Let n = len(vocab).\n",
    "  Returns:\n",
    "    tc_matrix: A nxn numpy array where A_ij contains the frequency with which\n",
    "        word j was found within context_window_size to the left or right of\n",
    "        word i in any sentence in the tuples.\n",
    "  '''\n",
    "  vocab_to_id = dict(zip(vocab, range(0, len(vocab))))\n",
    "  tc_matrix = np.zeros(shape=(len(vocab), len(vocab)))\n",
    "  for tuple in tuples:\n",
    "        words = tuple[1]\n",
    "       # print(\"###### NEW LINE\")\n",
    "       # print(words)\n",
    "        # un-comment these to see what's happening!\n",
    "        \n",
    "        for i in range(0, len(words)):\n",
    "            target_word = str(words[i])\n",
    "            target_word_id = vocab_to_id[target_word]\n",
    "            left_context = words[i-context_window_size:i]\n",
    "            right_context = words[i+1:i+context_window_size + 1]\n",
    "            \n",
    "            #print(\"### Target Word\")\n",
    "            #print(target_word)\n",
    "            #print(\"Left Context\")\n",
    "            #print(left_context)\n",
    "            #print(\"Right Context\")\n",
    "            #print(right_context)\n",
    "            # you can un-comment these to see what's going on!  Also, try different \"Context window\" sizes.\n",
    "            \n",
    "            for context_word in left_context + right_context:\n",
    "                context_word_id = vocab_to_id[context_word]\n",
    "                tc_matrix[target_word_id, context_word_id] += 1\n",
    "            i += 1\n",
    "\n",
    " # print(\"Word IDs\") -- you can un-comment this if you want!\n",
    "  #for key in vocab_to_id.keys():\n",
    "   #     print(key + \": \" + str(vocab_to_id[key]))\n",
    "  return tc_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 2.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [2. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(create_term_context_matrix(line_tuples_demo, vocab_demo, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "What does this matrix represent?  Please choose a single cell of the matrix, indicate the row/column of this cell, and then explain its meaning.  (How do these numbers relate to \"cheese\", \"crackers\", \"and\", \"wine\")?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 2\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Please change the \"context window\" to 2, and re-run the term-context matrix code.  What happens and why?  Again, please choose a single cell of the matrix and explain its meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 3\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPMI matrix\n",
    "\n",
    "Now we'll create a PPMI matrix.  Please refer to the Jurafsky and Martin \"Vector Semantics\" chapter for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_PPMI_matrix(term_context_matrix, k=0.01):\n",
    "  '''Given a term context matrix, output a PPMI matrix.\n",
    "  See section 15.1 in the textbook.\n",
    "  Input:\n",
    "    term_context_matrix: A nxn numpy array, where n is\n",
    "        the numer of tokens in the vocab.\n",
    "  Returns: A nxn numpy matrix, where A_ij is equal to the\n",
    "     point-wise mutual information between the ith word\n",
    "     and the jth word in the term_context_matrix.\n",
    "  ''' \n",
    "  term_context_matrix += k # add constant k to each element to eliminate zeros (LaPlace smoothing)\n",
    "  total_sum = np.sum(term_context_matrix)\n",
    "  print(\"total sum: \" + str(total_sum))\n",
    "  Pij = term_context_matrix / total_sum\n",
    "  Pi = np.sum(term_context_matrix,axis=1) / total_sum\n",
    "  Pj = np.sum(term_context_matrix,axis=0) / total_sum\n",
    "  PiTimesPj = np.outer(Pi, Pj)\n",
    "  ppmi = np.where(np.log2(Pij / (PiTimesPj)) > 0, np.log2(Pij / (PiTimesPj)), 0)\n",
    "    # keep only the ppmi elements greater than 0.\n",
    "  return ppmi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sum: 8.16\n",
      "[[0.         0.97198562 0.97198562 0.99284021]\n",
      " [0.97198562 0.         0.         0.        ]\n",
      " [0.97198562 0.         0.         0.        ]\n",
      " [0.99284021 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(create_PPMI_matrix(create_term_context_matrix(line_tuples_demo, vocab_demo, context_window_size=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Please choose a cell of this PPMI matrix, identify which row/column you are referring to, and explain what the value in this cell means as well as how it is calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 4\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Now please re-run the code that generates a term-context matrix and a PPMI matrix, but this time using a context window of 2 rather than 1.  For each of the matrices that you generate (the new term-context matrix and the new PPMI matrix), please again choose a cell and explain what it means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 5\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "The code used to create the PPMI matrix is \"vectorized\".  Please explain what that means.  Feel free to Google around.\n",
    "\n",
    "If you can, please also write a for-loop which would calculate the value of each individual cell of the PPMI matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 6\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf matrix\n",
    "\n",
    "Now we'll create a tf-idf matrix: a matrix indicating, for each word, its tf-idf among our collection of documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term document matrix\n",
      "number of words =4\n",
      "number of documents = 2\n",
      "[[1. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "tf-idf matrix\n",
      "number of words =4\n",
      "number of documents = 2\n",
      "[[0.         0.        ]\n",
      " [0.         0.69314718]\n",
      " [0.69314718 0.        ]\n",
      " [0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def create_tf_idf_matrix(term_document_matrix):\n",
    "  '''Given the term document matrix, output a tf-idf weighted version.\n",
    "  Input:\n",
    "    term_document_matrix: Numpy array where each column represents a document \n",
    "    and each row, the frequency of a word in that document.\n",
    "\n",
    "  Returns:\n",
    "    A numpy array with the same dimension as term_document_matrix, where\n",
    "    A_ij is weighted by the inverse document frequency of document h.\n",
    "  '''\n",
    "  N_docs = term_document_matrix.shape[1] # number of columns of the matrix = number of documents\n",
    "  idf = np.count_nonzero(term_document_matrix, axis=1) # this calculates doc frequency of each term\n",
    "  tfidf = (np.log(N_docs / idf) * term_document_matrix.T).T\n",
    "  return tfidf\n",
    "\n",
    "print(\"term document matrix\")\n",
    "print(create_term_document_matrix(line_tuples_demo, doc_names_demo, vocab_demo))\n",
    "print(\"tf-idf matrix\")\n",
    "print(create_tf_idf_matrix((create_term_document_matrix(line_tuples_demo, doc_names_demo, vocab_demo))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Please choose a cell in this matrix and explain what the value in it means and how it is calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 7\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write code to compute the cosine similarity between vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "1.0\n",
      "0.9746318461970761\n",
      "0.8536086925965384\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "def compute_cosine_similarity(vector1, vector2):\n",
    "  '''Computes the cosine similarity of the two input vectors.\n",
    "\n",
    "  Inputs:\n",
    "    vector1: A nx1 numpy array\n",
    "    vector2: A nx1 numpy array\n",
    "\n",
    "  Returns:\n",
    "    A scalar similarity value.\n",
    "  '''\n",
    "  \n",
    "  return 1 - spatial.distance.cosine(vector1, vector2)\n",
    "\n",
    "print(compute_cosine_similarity([1,2,3], [3,2,1]))\n",
    "print(compute_cosine_similarity([1,2,3], [10,20,30]))\n",
    "print(compute_cosine_similarity([1,2,3], [4,5,6]))\n",
    "print(compute_cosine_similarity([1,2,3], [3,30,300]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "What is cosine similarity?   What is the range of possible values that it can yield?  (Feel free to read online about this to come up with your answer.)  Can you explain the outputs printed above on an intuitive or conceptual level?  What does a \"higher\" number mean?  What does a \"lower\" number mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your anwer to Question 8\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will write a function which ranks the similarity of all documents to a single target document.   In the spirit of the Honor Code, I acknowledge that some of this code is from Stack Exchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words =4\n",
      "number of documents = 2\n",
      "[[1. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Index of the document most similar document to Doc1 is.... \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "def rank_docs(target_doc_index, term_document_matrix):\n",
    "  ''' Ranks the similarity of all of the plays to the target play.\n",
    "  Inputs:\n",
    "    target_doc_index: The integer index of the doc we want to compare all others against.\n",
    "    term_document_matrix: The term-document matrix as a mxn numpy array.\n",
    "\n",
    "  Returns:\n",
    "    The integer index of the doc with the least (cosine) distance to the doc indexed by target_doc_index.\n",
    "  '''\n",
    "\n",
    "  target = term_document_matrix.T[target_doc_index]\n",
    " # print(\"target\")\n",
    " # print(target) you can uncomment these if you want to see it\n",
    "  vectors = list(term_document_matrix.T)\n",
    " # print(\"vectors\")\n",
    " # print(vectors)\n",
    "  distances = distance.cdist([target], vectors, \"cosine\")[0]\n",
    "  min_index = np.argpartition(distances, 1)[1] # this gets the SECOND-closest vector\n",
    "                # because the CLOSEST vector is always the target vector itself.\n",
    "\n",
    "  return min_index\n",
    "\n",
    "\n",
    "\n",
    "term_doc_matrix = create_term_document_matrix(line_tuples_demo, doc_names_demo, vocab_demo)\n",
    "print(term_doc_matrix)\n",
    "\n",
    "print(\"Index of the document most similar document to Doc1 is.... \")\n",
    "print(rank_docs(1, term_doc_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "What happened here?  What does \"0\" mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 9\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll write code to try to find the most similar WORD to another word, based on the term-context-matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 2.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [2. 0. 0. 0.]]\n",
      "Index of the word most similar to Word3 is.... \n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def rank_words(target_word_index, term_context_matrix):\n",
    "  ''' Ranks the similarity of all of the words to the target word.\n",
    "\n",
    "  Inputs:\n",
    "    target_word_index: The index of the word we want to compare all others against.\n",
    "    term_context_matrix: Numpy matrix where the ith row represents a vector embedding of the ith word.\n",
    "\n",
    "  Returns:\n",
    "    A length-n list of integer word indices, ordered by decreasing (cosine) similarity to the \n",
    "    target word indexed by word_index\n",
    "  '''\n",
    "\n",
    "  target = term_context_matrix.T[target_word_index]\n",
    " # print(\"target\")\n",
    " # print(target) you can uncomment these if you want to see it\n",
    "  vectors = list(term_context_matrix.T)\n",
    " # print(\"vectors\")\n",
    " # print(vectors)\n",
    "  distances = distance.cdist([target], vectors, \"cosine\")[0]\n",
    "  min_index = np.argpartition(distances, 1)[1] # this gets the SECOND-closest vector\n",
    "                # because the CLOSEST vector is always the target vector itself.\n",
    "\n",
    "  return min_index\n",
    "\n",
    "\n",
    "\n",
    "term_context_matrix = create_term_context_matrix(line_tuples_demo, vocab_demo, 1)\n",
    "print(term_context_matrix)\n",
    "\n",
    "print(\"Index of the word most similar to Word3 is.... \")\n",
    "print(rank_words(3, term_context_matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "What does this mean?  What is Word3?  What is Word1?  Why is Word1 similar to Word3?  (How does all this relate to cheese, crackers, and wine?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 10\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Question 11\n",
    "\n",
    "Why is it useful to run our code on a tiny corpus instead of a much bigger one?  When you do big data projects, do you also practice and debug on a tiny subset of the data?  Why or why not?\n",
    "\n",
    "Also -- this homework uses Numpy arrays (mainly because those were used in the source material that this is adapted from), but it would actually be better to use Pandas dataframes where it is easier to label rows and columns.  If you are feeling ambitious, can you make a Pandas array of our term-by-document matrix (for doc1=\"cheese and crackers\", doc2= \"wine and cheese\") with the rows and columns labeled in an easy-to-read manner?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 11\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "\n",
    "Please read this article: https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017 and then indicate FIVE substantive facts that you learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 12\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13\n",
    "\n",
    "Please try out AllenNLP's \"textual entailment\" tool: https://demo.allennlp.org/textual-entailment\n",
    "\n",
    "How do you think this tool was built?  How good is it?  What types of sentence pairs can it handle well, what pairs does it struggle with, and why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 13\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "What do you think you will do for your final project in this class?  Please write a few sentences so that I can give you some feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your answer to Question 14\n",
    "\n",
    "goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
